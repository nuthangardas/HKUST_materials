{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.225e+01, 1.730e+00, 2.120e+00, ..., 1.000e+00, 3.170e+00,\n",
       "        5.100e+02],\n",
       "       [1.475e+01, 1.730e+00, 2.390e+00, ..., 1.250e+00, 2.730e+00,\n",
       "        1.150e+03],\n",
       "       [1.200e+01, 1.510e+00, 2.420e+00, ..., 1.050e+00, 2.650e+00,\n",
       "        4.500e+02],\n",
       "       ...,\n",
       "       [1.267e+01, 9.800e-01, 2.240e+00, ..., 1.230e+00, 3.160e+00,\n",
       "        4.500e+02],\n",
       "       [1.311e+01, 1.010e+00, 1.700e+00, ..., 1.120e+00, 3.180e+00,\n",
       "        5.020e+02],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input data\n",
    "data=np.load(\"/Users/gardasnagarjun/Downloads/datasets/bi-class/wine.npz\", mmap_mode='r')\n",
    "X_train=data['train_X'].astype('float32')\n",
    "train_Y=data['train_Y'].astype('long')\n",
    "X_test,test_Y=data['test_X'].astype('float32'),data['test_Y'].astype('long')\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "# training dataset is split into train, validation dataset\n",
    "train_X,val_X,train_y,val_Y=train_test_split(X_train,train_Y,test_size=0.2)\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 13) (29, 13) (113,) (29,)\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "#checking the shape\n",
    "print(train_X.shape,val_X.shape,train_y.shape,val_Y.shape)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13])\n",
      "torch.Size([2, 13])\n",
      "torch.Size([1, 13])\n",
      "torch.Size([1, 13])\n"
     ]
    }
   ],
   "source": [
    "#Construct main,train,validation and test datasets for torch.util.data.dataloader:\n",
    "\n",
    "main_data=[]\n",
    "for i in range(len(X_train)):\n",
    "    X_train.astype('float32')\n",
    "    train_Y.astype('long')\n",
    "    main_data.append([X_train[i],train_Y[i]])\n",
    "    \n",
    "mainloader=torch.utils.data.DataLoader(main_data,shuffle=True,batch_size=1)\n",
    "i4,l4=next(iter(mainloader))\n",
    "print(i4.shape)\n",
    "\n",
    "train_data = []\n",
    "for i in range(len(train_X)):\n",
    "    train_X.astype('float32')\n",
    "    train_y.astype('long')\n",
    "    train_data.append([train_X[i], train_y[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=2)\n",
    "i1, l1 = next(iter(trainloader))\n",
    "print(i1.shape)\n",
    "\n",
    "val_data=[]\n",
    "for i in range(len(val_X)):\n",
    "    val_X.astype('float32')\n",
    "    val_Y.astype('long')\n",
    "    val_data.append([val_X[i], val_Y[i]])\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=1)\n",
    "i2, l2 = next(iter(valloader))\n",
    "print(i2.shape)\n",
    "\n",
    "\n",
    "test_data=[]\n",
    "for i in range(len(X_test)):\n",
    "    X_test.astype('float32')\n",
    "    test_Y.astype('long')\n",
    "    test_data.append([X_test[i],test_Y[i]])\n",
    "    \n",
    "testloader=torch.utils.data.DataLoader(test_data,shuffle=False)\n",
    "\n",
    "i3,l3=next(iter(testloader))\n",
    "print(i3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "57\n",
      "29\n",
      "36\n",
      "0 [tensor([[1.2720e+01, 1.8100e+00, 2.2000e+00, 1.8800e+01, 8.6000e+01, 2.2000e+00,\n",
      "         2.5300e+00, 2.6000e-01, 1.7700e+00, 3.9000e+00, 1.1600e+00, 3.1400e+00,\n",
      "         7.1400e+02]]), tensor([1])]\n"
     ]
    }
   ],
   "source": [
    "print(len(mainloader))\n",
    "print(len(trainloader))\n",
    "print(len(valloader))\n",
    "print(len(testloader))\n",
    "for i,j in enumerate(valloader):\n",
    "    print(i,j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define the model of your Neural Network:\n",
    "class One_hidden(nn.Module):\n",
    "    def __init__(self,n_hidden,n_output=2,n_feature=13):\n",
    "        super(One_hidden,self).__init__()\n",
    "        self.hidden=nn.Linear(n_feature,n_hidden)\n",
    "        self.output=nn.Linear(n_hidden,n_output)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.hidden(x))\n",
    "        x=self.output(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One_hidden(\n",
      "  (hidden): Linear(in_features=13, out_features=10, bias=True)\n",
      "  (output): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# to check whether the model is defined or not\n",
    "net_10=One_hidden(10)\n",
    "print(net_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# step parameter is used to train the model\n",
    "# loss is generated along with step size defined\n",
    "def train_with_steps(net,trainloader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    #torch.manual_seed(0)\n",
    "    n_total_steps = len(trainloader)\n",
    "    num_epochs=20\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i,(x,y) in enumerate(trainloader):\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # Forward pass    \n",
    "            output = net(x)\n",
    "            loss = criterion(output, y)\n",
    "        \n",
    "        \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            if (i+1) % n_total_steps == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}],Step:[{i+1}/{n_total_steps}], Loss: {loss.item():.5f}')\n",
    "                \n",
    "    acc=accuracy(net,valloader)\n",
    "    return acc\n",
    "            \n",
    " #Calculate Accuracy:      \n",
    "def accuracy(net,valloader):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct=0\n",
    "        n_samples=0\n",
    "        for x,y in valloader:\n",
    "            output=net(x)\n",
    "            _,predicted=torch.max(output.data,1)\n",
    "            n_samples+=y.size(0)\n",
    "            n_correct+=(predicted==y).sum().item()\n",
    "            \n",
    "        acc=100.0* n_correct/n_samples\n",
    "        print(f'Accuracy of the network for val data: {acc} %')\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(net,testloader):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for z, y in testloader:\n",
    "            outputs = net(z)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += y.size(0)\n",
    "            n_correct += (predicted == y).sum().item()\n",
    "            \n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network for test data: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=(i for i in range(1,11))\n",
    "storage=dict()\n",
    "\n",
    "for i in n_hidden:\n",
    "    net=One_hidden(i)\n",
    "    storage[i]=train_with_steps(net,trainloader)\n",
    "\n",
    "print(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_best=One_hidden(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_steps(net_best,mainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(net_best,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is trained over average loss per epoch:\n",
    "\n",
    "def model_train(net,trainloader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    # number of epochs to train the model\n",
    "    n_epochs = 30  # suggest training between 20-50 epochs\n",
    "    loss_values=[]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "        train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "        for data, target in trainloader:\n",
    "        # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = net(data)\n",
    "        # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "        # update running training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "        train_loss = train_loss/len(trainloader.dataset)\n",
    "        loss_values.append(train_loss)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch+1, \n",
    "            train_loss\n",
    "            ))\n",
    "    plt.plot(loss_values)\n",
    "    acc=accuracy(net,valloader)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(net_best,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.941922\n",
      "Epoch: 2 \tTraining Loss: 0.771126\n",
      "Epoch: 3 \tTraining Loss: 0.750215\n",
      "Epoch: 4 \tTraining Loss: 0.731206\n",
      "Epoch: 5 \tTraining Loss: 0.734654\n",
      "Epoch: 6 \tTraining Loss: 0.703535\n",
      "Epoch: 7 \tTraining Loss: 0.703398\n",
      "Epoch: 8 \tTraining Loss: 0.687052\n",
      "Epoch: 9 \tTraining Loss: 0.677154\n",
      "Epoch: 10 \tTraining Loss: 0.658161\n",
      "Epoch: 11 \tTraining Loss: 0.648359\n",
      "Epoch: 12 \tTraining Loss: 0.638783\n",
      "Epoch: 13 \tTraining Loss: 0.624172\n",
      "Epoch: 14 \tTraining Loss: 0.634528\n",
      "Epoch: 15 \tTraining Loss: 0.606378\n",
      "Epoch: 16 \tTraining Loss: 0.593950\n",
      "Epoch: 17 \tTraining Loss: 0.592581\n",
      "Epoch: 18 \tTraining Loss: 0.586486\n",
      "Epoch: 19 \tTraining Loss: 0.590485\n",
      "Epoch: 20 \tTraining Loss: 0.565554\n",
      "Epoch: 21 \tTraining Loss: 0.566561\n",
      "Epoch: 22 \tTraining Loss: 0.560965\n",
      "Epoch: 23 \tTraining Loss: 0.562710\n",
      "Epoch: 24 \tTraining Loss: 0.541115\n",
      "Epoch: 25 \tTraining Loss: 0.562856\n",
      "Epoch: 26 \tTraining Loss: 0.547290\n",
      "Epoch: 27 \tTraining Loss: 0.526144\n",
      "Epoch: 28 \tTraining Loss: 0.532924\n",
      "Epoch: 29 \tTraining Loss: 0.529913\n",
      "Epoch: 30 \tTraining Loss: 0.533107\n",
      "Accuracy of the network for val data: 86.20689655172414 %\n",
      "Epoch: 1 \tTraining Loss: 68.449178\n",
      "Epoch: 2 \tTraining Loss: 42.316515\n",
      "Epoch: 3 \tTraining Loss: 22.950480\n",
      "Epoch: 4 \tTraining Loss: 8.493839\n",
      "Epoch: 5 \tTraining Loss: 1.325706\n",
      "Epoch: 6 \tTraining Loss: 0.708601\n",
      "Epoch: 7 \tTraining Loss: 0.701344\n",
      "Epoch: 8 \tTraining Loss: 0.698946\n",
      "Epoch: 9 \tTraining Loss: 0.696869\n",
      "Epoch: 10 \tTraining Loss: 0.694752\n",
      "Epoch: 11 \tTraining Loss: 0.692871\n",
      "Epoch: 12 \tTraining Loss: 0.691095\n",
      "Epoch: 13 \tTraining Loss: 0.689606\n",
      "Epoch: 14 \tTraining Loss: 0.688139\n",
      "Epoch: 15 \tTraining Loss: 0.686844\n",
      "Epoch: 16 \tTraining Loss: 0.685565\n",
      "Epoch: 17 \tTraining Loss: 0.684745\n",
      "Epoch: 18 \tTraining Loss: 0.683515\n",
      "Epoch: 19 \tTraining Loss: 0.682512\n",
      "Epoch: 20 \tTraining Loss: 0.681640\n",
      "Epoch: 21 \tTraining Loss: 0.680862\n",
      "Epoch: 22 \tTraining Loss: 0.680316\n",
      "Epoch: 23 \tTraining Loss: 0.679819\n",
      "Epoch: 24 \tTraining Loss: 0.679503\n",
      "Epoch: 25 \tTraining Loss: 0.679018\n",
      "Epoch: 26 \tTraining Loss: 0.678316\n",
      "Epoch: 27 \tTraining Loss: 0.678025\n",
      "Epoch: 28 \tTraining Loss: 0.677681\n",
      "Epoch: 29 \tTraining Loss: 0.677578\n",
      "Epoch: 30 \tTraining Loss: 0.677434\n",
      "Accuracy of the network for val data: 62.06896551724138 %\n",
      "Epoch: 1 \tTraining Loss: 3.049248\n",
      "Epoch: 2 \tTraining Loss: 0.690651\n",
      "Epoch: 3 \tTraining Loss: 0.683725\n",
      "Epoch: 4 \tTraining Loss: 0.682826\n",
      "Epoch: 5 \tTraining Loss: 0.682086\n",
      "Epoch: 6 \tTraining Loss: 0.681355\n",
      "Epoch: 7 \tTraining Loss: 0.680742\n",
      "Epoch: 8 \tTraining Loss: 0.680170\n",
      "Epoch: 9 \tTraining Loss: 0.679440\n",
      "Epoch: 10 \tTraining Loss: 0.679006\n",
      "Epoch: 11 \tTraining Loss: 0.678574\n",
      "Epoch: 12 \tTraining Loss: 0.678273\n",
      "Epoch: 13 \tTraining Loss: 0.677870\n",
      "Epoch: 14 \tTraining Loss: 0.677457\n",
      "Epoch: 15 \tTraining Loss: 0.677439\n",
      "Epoch: 16 \tTraining Loss: 0.677182\n",
      "Epoch: 17 \tTraining Loss: 0.677051\n",
      "Epoch: 18 \tTraining Loss: 0.676773\n",
      "Epoch: 19 \tTraining Loss: 0.676627\n",
      "Epoch: 20 \tTraining Loss: 0.676538\n",
      "Epoch: 21 \tTraining Loss: 0.676479\n",
      "Epoch: 22 \tTraining Loss: 0.676542\n",
      "Epoch: 23 \tTraining Loss: 0.676385\n",
      "Epoch: 24 \tTraining Loss: 0.676684\n",
      "Epoch: 25 \tTraining Loss: 0.676267\n",
      "Epoch: 26 \tTraining Loss: 0.676480\n",
      "Epoch: 27 \tTraining Loss: 0.676107\n",
      "Epoch: 28 \tTraining Loss: 0.676170\n",
      "Epoch: 29 \tTraining Loss: 0.676142\n",
      "Epoch: 30 \tTraining Loss: 0.676051\n",
      "Accuracy of the network for val data: 62.06896551724138 %\n",
      "Epoch: 1 \tTraining Loss: 4.791614\n",
      "Epoch: 2 \tTraining Loss: 1.248136\n",
      "Epoch: 3 \tTraining Loss: 0.606931\n",
      "Epoch: 4 \tTraining Loss: 0.590551\n",
      "Epoch: 5 \tTraining Loss: 0.584618\n",
      "Epoch: 6 \tTraining Loss: 0.583663\n",
      "Epoch: 7 \tTraining Loss: 0.585043\n",
      "Epoch: 8 \tTraining Loss: 0.577405\n",
      "Epoch: 9 \tTraining Loss: 0.577493\n",
      "Epoch: 10 \tTraining Loss: 0.571462\n",
      "Epoch: 11 \tTraining Loss: 0.567576\n",
      "Epoch: 12 \tTraining Loss: 0.577865\n",
      "Epoch: 13 \tTraining Loss: 0.564507\n",
      "Epoch: 14 \tTraining Loss: 0.555628\n",
      "Epoch: 15 \tTraining Loss: 0.553354\n",
      "Epoch: 16 \tTraining Loss: 0.550227\n",
      "Epoch: 17 \tTraining Loss: 0.540827\n",
      "Epoch: 18 \tTraining Loss: 0.537575\n",
      "Epoch: 19 \tTraining Loss: 0.534297\n",
      "Epoch: 20 \tTraining Loss: 0.528434\n",
      "Epoch: 21 \tTraining Loss: 0.522417\n",
      "Epoch: 22 \tTraining Loss: 0.519277\n",
      "Epoch: 23 \tTraining Loss: 0.509703\n",
      "Epoch: 24 \tTraining Loss: 0.506195\n",
      "Epoch: 25 \tTraining Loss: 0.499552\n",
      "Epoch: 26 \tTraining Loss: 0.490231\n",
      "Epoch: 27 \tTraining Loss: 0.485432\n",
      "Epoch: 28 \tTraining Loss: 0.479764\n",
      "Epoch: 29 \tTraining Loss: 0.476398\n",
      "Epoch: 30 \tTraining Loss: 0.473679\n",
      "Accuracy of the network for val data: 82.75862068965517 %\n",
      "Epoch: 1 \tTraining Loss: 11.799710\n",
      "Epoch: 2 \tTraining Loss: 0.939760\n",
      "Epoch: 3 \tTraining Loss: 0.501578\n",
      "Epoch: 4 \tTraining Loss: 0.562358\n",
      "Epoch: 5 \tTraining Loss: 0.466791\n",
      "Epoch: 6 \tTraining Loss: 0.438313\n",
      "Epoch: 7 \tTraining Loss: 0.606080\n",
      "Epoch: 8 \tTraining Loss: 0.441941\n",
      "Epoch: 9 \tTraining Loss: 0.431470\n",
      "Epoch: 10 \tTraining Loss: 0.507098\n",
      "Epoch: 11 \tTraining Loss: 0.494625\n",
      "Epoch: 12 \tTraining Loss: 0.387162\n",
      "Epoch: 13 \tTraining Loss: 0.375480\n",
      "Epoch: 14 \tTraining Loss: 0.422526\n",
      "Epoch: 15 \tTraining Loss: 0.405950\n",
      "Epoch: 16 \tTraining Loss: 0.387641\n",
      "Epoch: 17 \tTraining Loss: 0.388895\n",
      "Epoch: 18 \tTraining Loss: 0.348428\n",
      "Epoch: 19 \tTraining Loss: 0.334333\n",
      "Epoch: 20 \tTraining Loss: 0.377262\n",
      "Epoch: 21 \tTraining Loss: 0.347789\n",
      "Epoch: 22 \tTraining Loss: 0.308108\n",
      "Epoch: 23 \tTraining Loss: 0.325101\n",
      "Epoch: 24 \tTraining Loss: 0.375968\n",
      "Epoch: 25 \tTraining Loss: 0.320119\n",
      "Epoch: 26 \tTraining Loss: 0.310769\n",
      "Epoch: 27 \tTraining Loss: 0.322546\n",
      "Epoch: 28 \tTraining Loss: 0.306501\n",
      "Epoch: 29 \tTraining Loss: 0.345336\n",
      "Epoch: 30 \tTraining Loss: 0.290342\n",
      "Accuracy of the network for val data: 86.20689655172414 %\n",
      "Epoch: 1 \tTraining Loss: 29.555352\n",
      "Epoch: 2 \tTraining Loss: 6.406167\n",
      "Epoch: 3 \tTraining Loss: 5.163994\n",
      "Epoch: 4 \tTraining Loss: 4.132537\n",
      "Epoch: 5 \tTraining Loss: 3.565479\n",
      "Epoch: 6 \tTraining Loss: 2.581044\n",
      "Epoch: 7 \tTraining Loss: 1.977090\n",
      "Epoch: 8 \tTraining Loss: 1.334755\n",
      "Epoch: 9 \tTraining Loss: 0.955252\n",
      "Epoch: 10 \tTraining Loss: 0.667741\n",
      "Epoch: 11 \tTraining Loss: 0.545622\n",
      "Epoch: 12 \tTraining Loss: 0.513787\n",
      "Epoch: 13 \tTraining Loss: 0.479913\n",
      "Epoch: 14 \tTraining Loss: 0.468085\n",
      "Epoch: 15 \tTraining Loss: 0.448246\n",
      "Epoch: 16 \tTraining Loss: 0.463223\n",
      "Epoch: 17 \tTraining Loss: 0.420701\n",
      "Epoch: 18 \tTraining Loss: 0.453618\n",
      "Epoch: 19 \tTraining Loss: 0.402078\n",
      "Epoch: 20 \tTraining Loss: 0.418861\n",
      "Epoch: 21 \tTraining Loss: 0.469207\n",
      "Epoch: 22 \tTraining Loss: 0.363139\n",
      "Epoch: 23 \tTraining Loss: 0.355491\n",
      "Epoch: 24 \tTraining Loss: 0.365390\n",
      "Epoch: 25 \tTraining Loss: 0.353705\n",
      "Epoch: 26 \tTraining Loss: 0.344435\n",
      "Epoch: 27 \tTraining Loss: 0.337021\n",
      "Epoch: 28 \tTraining Loss: 0.364309\n",
      "Epoch: 29 \tTraining Loss: 0.345864\n",
      "Epoch: 30 \tTraining Loss: 0.329094\n",
      "Accuracy of the network for val data: 79.3103448275862 %\n",
      "Epoch: 1 \tTraining Loss: 2.232133\n",
      "Epoch: 2 \tTraining Loss: 1.045074\n",
      "Epoch: 3 \tTraining Loss: 0.627940\n",
      "Epoch: 4 \tTraining Loss: 0.576800\n",
      "Epoch: 5 \tTraining Loss: 0.513912\n",
      "Epoch: 6 \tTraining Loss: 0.490659\n",
      "Epoch: 7 \tTraining Loss: 0.484854\n",
      "Epoch: 8 \tTraining Loss: 0.464415\n",
      "Epoch: 9 \tTraining Loss: 0.449348\n",
      "Epoch: 10 \tTraining Loss: 0.424584\n",
      "Epoch: 11 \tTraining Loss: 0.451339\n",
      "Epoch: 12 \tTraining Loss: 0.416950\n",
      "Epoch: 13 \tTraining Loss: 0.387299\n",
      "Epoch: 14 \tTraining Loss: 0.424605\n",
      "Epoch: 15 \tTraining Loss: 0.421018\n",
      "Epoch: 16 \tTraining Loss: 0.372960\n",
      "Epoch: 17 \tTraining Loss: 0.361854\n",
      "Epoch: 18 \tTraining Loss: 0.322913\n",
      "Epoch: 19 \tTraining Loss: 0.366186\n",
      "Epoch: 20 \tTraining Loss: 0.350723\n",
      "Epoch: 21 \tTraining Loss: 0.300989\n",
      "Epoch: 22 \tTraining Loss: 0.353683\n",
      "Epoch: 23 \tTraining Loss: 0.325023\n",
      "Epoch: 24 \tTraining Loss: 0.305801\n",
      "Epoch: 25 \tTraining Loss: 0.305887\n",
      "Epoch: 26 \tTraining Loss: 0.303463\n",
      "Epoch: 27 \tTraining Loss: 0.331490\n",
      "Epoch: 28 \tTraining Loss: 0.327748\n",
      "Epoch: 29 \tTraining Loss: 0.302439\n",
      "Epoch: 30 \tTraining Loss: 0.292368\n",
      "Accuracy of the network for val data: 96.55172413793103 %\n",
      "Epoch: 1 \tTraining Loss: 0.872046\n",
      "Epoch: 2 \tTraining Loss: 0.481668\n",
      "Epoch: 3 \tTraining Loss: 0.562053\n",
      "Epoch: 4 \tTraining Loss: 0.473880\n",
      "Epoch: 5 \tTraining Loss: 0.452344\n",
      "Epoch: 6 \tTraining Loss: 0.476482\n",
      "Epoch: 7 \tTraining Loss: 0.512811\n",
      "Epoch: 8 \tTraining Loss: 0.465032\n",
      "Epoch: 9 \tTraining Loss: 0.473601\n",
      "Epoch: 10 \tTraining Loss: 0.436743\n",
      "Epoch: 11 \tTraining Loss: 0.455026\n",
      "Epoch: 12 \tTraining Loss: 0.404768\n",
      "Epoch: 13 \tTraining Loss: 0.395080\n",
      "Epoch: 14 \tTraining Loss: 0.395980\n",
      "Epoch: 15 \tTraining Loss: 0.391058\n",
      "Epoch: 16 \tTraining Loss: 0.407941\n",
      "Epoch: 17 \tTraining Loss: 0.355383\n",
      "Epoch: 18 \tTraining Loss: 0.374388\n",
      "Epoch: 19 \tTraining Loss: 0.350078\n",
      "Epoch: 20 \tTraining Loss: 0.344721\n",
      "Epoch: 21 \tTraining Loss: 0.360111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 \tTraining Loss: 0.316107\n",
      "Epoch: 23 \tTraining Loss: 0.361811\n",
      "Epoch: 24 \tTraining Loss: 0.289141\n",
      "Epoch: 25 \tTraining Loss: 0.313200\n",
      "Epoch: 26 \tTraining Loss: 0.393034\n",
      "Epoch: 27 \tTraining Loss: 0.319905\n",
      "Epoch: 28 \tTraining Loss: 0.352040\n",
      "Epoch: 29 \tTraining Loss: 0.271518\n",
      "Epoch: 30 \tTraining Loss: 0.257488\n",
      "Accuracy of the network for val data: 82.75862068965517 %\n",
      "Epoch: 1 \tTraining Loss: 2.436196\n",
      "Epoch: 2 \tTraining Loss: 0.533713\n",
      "Epoch: 3 \tTraining Loss: 0.552405\n",
      "Epoch: 4 \tTraining Loss: 0.595899\n",
      "Epoch: 5 \tTraining Loss: 0.501958\n",
      "Epoch: 6 \tTraining Loss: 0.466973\n",
      "Epoch: 7 \tTraining Loss: 0.628571\n",
      "Epoch: 8 \tTraining Loss: 0.479478\n",
      "Epoch: 9 \tTraining Loss: 0.444321\n",
      "Epoch: 10 \tTraining Loss: 0.389852\n",
      "Epoch: 11 \tTraining Loss: 0.403230\n",
      "Epoch: 12 \tTraining Loss: 0.421326\n",
      "Epoch: 13 \tTraining Loss: 0.410196\n",
      "Epoch: 14 \tTraining Loss: 0.397524\n",
      "Epoch: 15 \tTraining Loss: 0.358941\n",
      "Epoch: 16 \tTraining Loss: 0.325436\n",
      "Epoch: 17 \tTraining Loss: 0.342222\n",
      "Epoch: 18 \tTraining Loss: 0.338933\n",
      "Epoch: 19 \tTraining Loss: 0.325431\n",
      "Epoch: 20 \tTraining Loss: 0.347985\n",
      "Epoch: 21 \tTraining Loss: 0.317495\n",
      "Epoch: 22 \tTraining Loss: 0.385419\n",
      "Epoch: 23 \tTraining Loss: 0.312294\n",
      "Epoch: 24 \tTraining Loss: 0.288161\n",
      "Epoch: 25 \tTraining Loss: 0.296138\n",
      "Epoch: 26 \tTraining Loss: 0.304335\n",
      "Epoch: 27 \tTraining Loss: 0.283866\n",
      "Epoch: 28 \tTraining Loss: 0.265625\n",
      "Epoch: 29 \tTraining Loss: 0.284931\n",
      "Epoch: 30 \tTraining Loss: 0.269713\n",
      "Accuracy of the network for val data: 96.55172413793103 %\n",
      "Epoch: 1 \tTraining Loss: 38.476959\n",
      "Epoch: 2 \tTraining Loss: 3.758159\n",
      "Epoch: 3 \tTraining Loss: 3.686403\n",
      "Epoch: 4 \tTraining Loss: 2.971852\n",
      "Epoch: 5 \tTraining Loss: 1.944484\n",
      "Epoch: 6 \tTraining Loss: 2.098621\n",
      "Epoch: 7 \tTraining Loss: 1.008862\n",
      "Epoch: 8 \tTraining Loss: 0.703910\n",
      "Epoch: 9 \tTraining Loss: 0.648164\n",
      "Epoch: 10 \tTraining Loss: 0.522084\n",
      "Epoch: 11 \tTraining Loss: 0.496746\n",
      "Epoch: 12 \tTraining Loss: 0.471804\n",
      "Epoch: 13 \tTraining Loss: 0.490103\n",
      "Epoch: 14 \tTraining Loss: 0.438616\n",
      "Epoch: 15 \tTraining Loss: 0.401684\n",
      "Epoch: 16 \tTraining Loss: 0.418637\n",
      "Epoch: 17 \tTraining Loss: 0.397247\n",
      "Epoch: 18 \tTraining Loss: 0.372223\n",
      "Epoch: 19 \tTraining Loss: 0.418204\n",
      "Epoch: 20 \tTraining Loss: 0.351915\n",
      "Epoch: 21 \tTraining Loss: 0.346548\n",
      "Epoch: 22 \tTraining Loss: 0.347837\n",
      "Epoch: 23 \tTraining Loss: 0.337970\n",
      "Epoch: 24 \tTraining Loss: 0.335823\n",
      "Epoch: 25 \tTraining Loss: 0.286741\n",
      "Epoch: 26 \tTraining Loss: 0.340880\n",
      "Epoch: 27 \tTraining Loss: 0.395364\n",
      "Epoch: 28 \tTraining Loss: 0.293621\n",
      "Epoch: 29 \tTraining Loss: 0.278298\n",
      "Epoch: 30 \tTraining Loss: 0.317458\n",
      "Accuracy of the network for val data: 93.10344827586206 %\n",
      "{1: 86.20689655172414, 2: 62.06896551724138, 3: 62.06896551724138, 4: 82.75862068965517, 5: 86.20689655172414, 6: 79.3103448275862, 7: 96.55172413793103, 8: 82.75862068965517, 9: 96.55172413793103, 10: 93.10344827586206}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to find the best hidden node, train and test the accuracies of such model, find the best one:\n",
    "\n",
    "n_hidden=(i for i in range(1,11))\n",
    "storage=dict()\n",
    "\n",
    "for i in n_hidden:\n",
    "    net=One_hidden(i)\n",
    "    storage[i]=model_train(net,trainloader)\n",
    "    \n",
    "print(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 4.145105\n",
      "Epoch: 2 \tTraining Loss: 0.534644\n",
      "Epoch: 3 \tTraining Loss: 0.552931\n",
      "Epoch: 4 \tTraining Loss: 0.690980\n",
      "Epoch: 5 \tTraining Loss: 0.531536\n",
      "Epoch: 6 \tTraining Loss: 0.421271\n",
      "Epoch: 7 \tTraining Loss: 0.421889\n",
      "Epoch: 8 \tTraining Loss: 0.461244\n",
      "Epoch: 9 \tTraining Loss: 0.421176\n",
      "Epoch: 10 \tTraining Loss: 0.401006\n",
      "Epoch: 11 \tTraining Loss: 0.401577\n",
      "Epoch: 12 \tTraining Loss: 0.380044\n",
      "Epoch: 13 \tTraining Loss: 0.342821\n",
      "Epoch: 14 \tTraining Loss: 0.357685\n",
      "Epoch: 15 \tTraining Loss: 0.338827\n",
      "Epoch: 16 \tTraining Loss: 0.323408\n",
      "Epoch: 17 \tTraining Loss: 0.370263\n",
      "Epoch: 18 \tTraining Loss: 0.304510\n",
      "Epoch: 19 \tTraining Loss: 0.295227\n",
      "Epoch: 20 \tTraining Loss: 0.299337\n",
      "Epoch: 21 \tTraining Loss: 0.317901\n",
      "Epoch: 22 \tTraining Loss: 0.269959\n",
      "Epoch: 23 \tTraining Loss: 0.244064\n",
      "Epoch: 24 \tTraining Loss: 0.269228\n",
      "Epoch: 25 \tTraining Loss: 0.257134\n",
      "Epoch: 26 \tTraining Loss: 0.286006\n",
      "Epoch: 27 \tTraining Loss: 0.254148\n",
      "Epoch: 28 \tTraining Loss: 0.253876\n",
      "Epoch: 29 \tTraining Loss: 0.259309\n",
      "Epoch: 30 \tTraining Loss: 0.215146\n",
      "Accuracy of the network for val data: 79.3103448275862 %\n",
      "Training time: 2.210202932357788s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time_best=time.time()\n",
    "model_best=One_hidden(7) # Best parameter\n",
    "model_train(model_best,mainloader)\n",
    "end_time_best=time.time()\n",
    "print(f\"Training time: {end_time_best-start_time_best}s\") # Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network for test data: 77.77777777777777 %\n"
     ]
    }
   ],
   "source": [
    "accuracy_test(model_best,testloader) # Final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
