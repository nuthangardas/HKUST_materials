{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphabet</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>feat15</th>\n",
       "      <th>feat16</th>\n",
       "      <th>feat17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>1:-0.733333</td>\n",
       "      <td>2:-0.466667</td>\n",
       "      <td>3:-0.466667</td>\n",
       "      <td>4:-0.6</td>\n",
       "      <td>5:-0.733333</td>\n",
       "      <td>6:-0.0666667</td>\n",
       "      <td>7:0.0666667</td>\n",
       "      <td>8:-0.733333</td>\n",
       "      <td>9:0.2</td>\n",
       "      <td>10:0.466667</td>\n",
       "      <td>11:-0.0666667</td>\n",
       "      <td>12:-0.0666667</td>\n",
       "      <td>13:-0.866667</td>\n",
       "      <td>14:0.0666667</td>\n",
       "      <td>15:-0.333333</td>\n",
       "      <td>16:-0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1:-0.466667</td>\n",
       "      <td>2:-0.0666667</td>\n",
       "      <td>3:-0.333333</td>\n",
       "      <td>4:-0.333333</td>\n",
       "      <td>5:-0.333333</td>\n",
       "      <td>6:-0.333333</td>\n",
       "      <td>7:0.2</td>\n",
       "      <td>8:-0.2</td>\n",
       "      <td>9:-0.466667</td>\n",
       "      <td>10:0.0666667</td>\n",
       "      <td>11:-0.0666667</td>\n",
       "      <td>12:0.2</td>\n",
       "      <td>13:-0.733333</td>\n",
       "      <td>14:0.2</td>\n",
       "      <td>15:-0.0666667</td>\n",
       "      <td>16:0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>1:-0.0666667</td>\n",
       "      <td>2:0.333333</td>\n",
       "      <td>3:0.0666667</td>\n",
       "      <td>4:-0.0666667</td>\n",
       "      <td>5:-0.466667</td>\n",
       "      <td>6:0.0666667</td>\n",
       "      <td>7:0.0666667</td>\n",
       "      <td>8:-0.333333</td>\n",
       "      <td>9:0.333333</td>\n",
       "      <td>10:0.466667</td>\n",
       "      <td>11:-0.733333</td>\n",
       "      <td>12:0.0666667</td>\n",
       "      <td>13:-0.733333</td>\n",
       "      <td>14:-0.333333</td>\n",
       "      <td>15:-0.333333</td>\n",
       "      <td>16:0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1:-0.466667</td>\n",
       "      <td>2:0.2</td>\n",
       "      <td>3:-0.333333</td>\n",
       "      <td>4:-0.0666667</td>\n",
       "      <td>5:-0.466667</td>\n",
       "      <td>6:-0.0666667</td>\n",
       "      <td>7:-0.0666667</td>\n",
       "      <td>8:0.733333</td>\n",
       "      <td>9:-0.866667</td>\n",
       "      <td>10:-0.0666667</td>\n",
       "      <td>11:-0.2</td>\n",
       "      <td>12:0.0666667</td>\n",
       "      <td>13:-0.6</td>\n",
       "      <td>14:0.0666667</td>\n",
       "      <td>15:-1</td>\n",
       "      <td>16:0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1:-0.2</td>\n",
       "      <td>2:-0.0666667</td>\n",
       "      <td>3:0.0666667</td>\n",
       "      <td>4:-0.333333</td>\n",
       "      <td>5:-0.466667</td>\n",
       "      <td>6:-0.0666667</td>\n",
       "      <td>7:-0.2</td>\n",
       "      <td>8:-0.6</td>\n",
       "      <td>9:-0.0666667</td>\n",
       "      <td>10:0.333333</td>\n",
       "      <td>11:-0.0666667</td>\n",
       "      <td>12:0.2</td>\n",
       "      <td>13:-0.6</td>\n",
       "      <td>14:0.0666667</td>\n",
       "      <td>15:-0.6</td>\n",
       "      <td>16:-0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alphabet         feat1         feat2        feat3         feat4  \\\n",
       "0        26   1:-0.733333   2:-0.466667  3:-0.466667        4:-0.6   \n",
       "1        16   1:-0.466667  2:-0.0666667  3:-0.333333   4:-0.333333   \n",
       "2        19  1:-0.0666667    2:0.333333  3:0.0666667  4:-0.0666667   \n",
       "3         8   1:-0.466667         2:0.2  3:-0.333333  4:-0.0666667   \n",
       "4         8        1:-0.2  2:-0.0666667  3:0.0666667   4:-0.333333   \n",
       "\n",
       "         feat5         feat6         feat7        feat8         feat9  \\\n",
       "0  5:-0.733333  6:-0.0666667   7:0.0666667  8:-0.733333         9:0.2   \n",
       "1  5:-0.333333   6:-0.333333         7:0.2       8:-0.2   9:-0.466667   \n",
       "2  5:-0.466667   6:0.0666667   7:0.0666667  8:-0.333333    9:0.333333   \n",
       "3  5:-0.466667  6:-0.0666667  7:-0.0666667   8:0.733333   9:-0.866667   \n",
       "4  5:-0.466667  6:-0.0666667        7:-0.2       8:-0.6  9:-0.0666667   \n",
       "\n",
       "          feat10         feat11         feat12        feat13        feat14  \\\n",
       "0    10:0.466667  11:-0.0666667  12:-0.0666667  13:-0.866667  14:0.0666667   \n",
       "1   10:0.0666667  11:-0.0666667         12:0.2  13:-0.733333        14:0.2   \n",
       "2    10:0.466667   11:-0.733333   12:0.0666667  13:-0.733333  14:-0.333333   \n",
       "3  10:-0.0666667        11:-0.2   12:0.0666667       13:-0.6  14:0.0666667   \n",
       "4    10:0.333333  11:-0.0666667         12:0.2       13:-0.6  14:0.0666667   \n",
       "\n",
       "          feat15         feat16  feat17  \n",
       "0   15:-0.333333        16:-0.2     NaN  \n",
       "1  15:-0.0666667    16:0.333333     NaN  \n",
       "2   15:-0.333333    16:0.333333     NaN  \n",
       "3          15:-1   16:0.0666667     NaN  \n",
       "4        15:-0.6  16:-0.0666667     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv(\"/Users/gardasnagarjun/Downloads/Assignment2_v3/Q1_dataset/letter_train\",sep=\" \",header=None)\n",
    "train_data.columns=['Alphabet','feat1','feat2','feat3','feat4','feat5','feat6','feat7','feat8','feat9','feat10','feat11','feat12','feat13','feat14','feat15','feat16','feat17']\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphabet</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>feat15</th>\n",
       "      <th>feat16</th>\n",
       "      <th>feat17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alphabet       feat1       feat2      feat3       feat4      feat5  \\\n",
       "0        26   -0.733333   -0.466667  -0.466667        -0.6  -0.733333   \n",
       "1        16   -0.466667  -0.0666667  -0.333333   -0.333333  -0.333333   \n",
       "2        19  -0.0666667    0.333333  0.0666667  -0.0666667  -0.466667   \n",
       "3         8   -0.466667         0.2  -0.333333  -0.0666667  -0.466667   \n",
       "4         8        -0.2  -0.0666667  0.0666667   -0.333333  -0.466667   \n",
       "\n",
       "        feat6       feat7      feat8       feat9      feat10      feat11  \\\n",
       "0  -0.0666667   0.0666667  -0.733333         0.2    0.466667  -0.0666667   \n",
       "1   -0.333333         0.2       -0.2   -0.466667   0.0666667  -0.0666667   \n",
       "2   0.0666667   0.0666667  -0.333333    0.333333    0.466667   -0.733333   \n",
       "3  -0.0666667  -0.0666667   0.733333   -0.866667  -0.0666667        -0.2   \n",
       "4  -0.0666667        -0.2       -0.6  -0.0666667    0.333333  -0.0666667   \n",
       "\n",
       "       feat12     feat13     feat14      feat15      feat16  feat17  \n",
       "0  -0.0666667  -0.866667  0.0666667   -0.333333        -0.2     NaN  \n",
       "1         0.2  -0.733333        0.2  -0.0666667    0.333333     NaN  \n",
       "2   0.0666667  -0.733333  -0.333333   -0.333333    0.333333     NaN  \n",
       "3   0.0666667       -0.6  0.0666667          -1   0.0666667     NaN  \n",
       "4         0.2       -0.6  0.0666667        -0.6  -0.0666667     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['feat1','feat2','feat3','feat4','feat5','feat6','feat7','feat8','feat9','feat10','feat11','feat12','feat13','feat14','feat15','feat16']\n",
    "\n",
    "for c in columns:\n",
    "    train_data[c] = train_data[c].str.split(':').str[1]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphabet</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>feat15</th>\n",
       "      <th>feat16</th>\n",
       "      <th>feat17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>1:-0.466667</td>\n",
       "      <td>2:-0.0666667</td>\n",
       "      <td>3:-0.333333</td>\n",
       "      <td>4:-0.2</td>\n",
       "      <td>5:-0.733333</td>\n",
       "      <td>6:0.0666667</td>\n",
       "      <td>7:-0.2</td>\n",
       "      <td>8:0.0666667</td>\n",
       "      <td>9:-0.2</td>\n",
       "      <td>10:-0.2</td>\n",
       "      <td>11:-0.2</td>\n",
       "      <td>12:0.0666667</td>\n",
       "      <td>13:-0.6</td>\n",
       "      <td>14:0.0666667</td>\n",
       "      <td>15:-0.466667</td>\n",
       "      <td>16:0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1:-0.6</td>\n",
       "      <td>2:0.2</td>\n",
       "      <td>3:-0.466667</td>\n",
       "      <td>4:-0.2</td>\n",
       "      <td>5:-0.6</td>\n",
       "      <td>6:-0.333333</td>\n",
       "      <td>7:0.333333</td>\n",
       "      <td>8:0.2</td>\n",
       "      <td>9:-0.6</td>\n",
       "      <td>10:-0.0666667</td>\n",
       "      <td>11:-0.466667</td>\n",
       "      <td>12:0.0666667</td>\n",
       "      <td>13:-0.6</td>\n",
       "      <td>14:-0.0666667</td>\n",
       "      <td>15:-0.2</td>\n",
       "      <td>16:0.466667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1:-0.733333</td>\n",
       "      <td>2:-0.866667</td>\n",
       "      <td>3:-0.733333</td>\n",
       "      <td>4:-0.733333</td>\n",
       "      <td>5:-0.866667</td>\n",
       "      <td>6:-0.333333</td>\n",
       "      <td>7:0.333333</td>\n",
       "      <td>8:-0.466667</td>\n",
       "      <td>9:-0.333333</td>\n",
       "      <td>10:0.333333</td>\n",
       "      <td>11:0.2</td>\n",
       "      <td>12:-0.2</td>\n",
       "      <td>13:-0.866667</td>\n",
       "      <td>14:0.2</td>\n",
       "      <td>15:-0.6</td>\n",
       "      <td>16:-0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1:-0.733333</td>\n",
       "      <td>2:-0.466667</td>\n",
       "      <td>3:-0.466667</td>\n",
       "      <td>4:-0.6</td>\n",
       "      <td>5:-0.733333</td>\n",
       "      <td>6:-0.0666667</td>\n",
       "      <td>7:0.2</td>\n",
       "      <td>8:-0.866667</td>\n",
       "      <td>9:-0.0666667</td>\n",
       "      <td>10:0.733333</td>\n",
       "      <td>11:-0.333333</td>\n",
       "      <td>12:-0.333333</td>\n",
       "      <td>13:-0.866667</td>\n",
       "      <td>14:0.2</td>\n",
       "      <td>15:-0.733333</td>\n",
       "      <td>16:0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>1:-0.333333</td>\n",
       "      <td>2:0.0666667</td>\n",
       "      <td>3:-0.2</td>\n",
       "      <td>4:-0.2</td>\n",
       "      <td>5:-0.6</td>\n",
       "      <td>6:-0.466667</td>\n",
       "      <td>7:0.733333</td>\n",
       "      <td>8:-0.466667</td>\n",
       "      <td>9:-0.2</td>\n",
       "      <td>10:0.6</td>\n",
       "      <td>11:0.333333</td>\n",
       "      <td>12:-0.466667</td>\n",
       "      <td>13:-0.733333</td>\n",
       "      <td>14:0.466667</td>\n",
       "      <td>15:-0.733333</td>\n",
       "      <td>16:-0.466667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alphabet        feat1         feat2        feat3        feat4        feat5  \\\n",
       "0        17  1:-0.466667  2:-0.0666667  3:-0.333333       4:-0.2  5:-0.733333   \n",
       "1        18       1:-0.6         2:0.2  3:-0.466667       4:-0.2       5:-0.6   \n",
       "2         6  1:-0.733333   2:-0.866667  3:-0.733333  4:-0.733333  5:-0.866667   \n",
       "3         6  1:-0.733333   2:-0.466667  3:-0.466667       4:-0.6  5:-0.733333   \n",
       "4        20  1:-0.333333   2:0.0666667       3:-0.2       4:-0.2       5:-0.6   \n",
       "\n",
       "          feat6       feat7        feat8         feat9         feat10  \\\n",
       "0   6:0.0666667      7:-0.2  8:0.0666667        9:-0.2        10:-0.2   \n",
       "1   6:-0.333333  7:0.333333        8:0.2        9:-0.6  10:-0.0666667   \n",
       "2   6:-0.333333  7:0.333333  8:-0.466667   9:-0.333333    10:0.333333   \n",
       "3  6:-0.0666667       7:0.2  8:-0.866667  9:-0.0666667    10:0.733333   \n",
       "4   6:-0.466667  7:0.733333  8:-0.466667        9:-0.2         10:0.6   \n",
       "\n",
       "         feat11        feat12        feat13         feat14        feat15  \\\n",
       "0       11:-0.2  12:0.0666667       13:-0.6   14:0.0666667  15:-0.466667   \n",
       "1  11:-0.466667  12:0.0666667       13:-0.6  14:-0.0666667       15:-0.2   \n",
       "2        11:0.2       12:-0.2  13:-0.866667         14:0.2       15:-0.6   \n",
       "3  11:-0.333333  12:-0.333333  13:-0.866667         14:0.2  15:-0.733333   \n",
       "4   11:0.333333  12:-0.466667  13:-0.733333    14:0.466667  15:-0.733333   \n",
       "\n",
       "          feat16  feat17  \n",
       "0   16:0.0666667     NaN  \n",
       "1    16:0.466667     NaN  \n",
       "2  16:-0.0666667     NaN  \n",
       "3   16:0.0666667     NaN  \n",
       "4   16:-0.466667     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv(\"/Users/gardasnagarjun/Downloads/Assignment2_v3/Q1_dataset/letter_test\",sep=\" \",header=None)\n",
    "test_data.columns=['Alphabet','feat1','feat2','feat3','feat4','feat5','feat6','feat7','feat8','feat9','feat10','feat11','feat12','feat13','feat14','feat15','feat16','feat17']\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphabet</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>feat15</th>\n",
       "      <th>feat16</th>\n",
       "      <th>feat17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alphabet      feat1       feat2      feat3      feat4      feat5  \\\n",
       "0        17  -0.466667  -0.0666667  -0.333333       -0.2  -0.733333   \n",
       "1        18       -0.6         0.2  -0.466667       -0.2       -0.6   \n",
       "2         6  -0.733333   -0.866667  -0.733333  -0.733333  -0.866667   \n",
       "3         6  -0.733333   -0.466667  -0.466667       -0.6  -0.733333   \n",
       "4        20  -0.333333   0.0666667       -0.2       -0.2       -0.6   \n",
       "\n",
       "        feat6     feat7      feat8       feat9      feat10     feat11  \\\n",
       "0   0.0666667      -0.2  0.0666667        -0.2        -0.2       -0.2   \n",
       "1   -0.333333  0.333333        0.2        -0.6  -0.0666667  -0.466667   \n",
       "2   -0.333333  0.333333  -0.466667   -0.333333    0.333333        0.2   \n",
       "3  -0.0666667       0.2  -0.866667  -0.0666667    0.733333  -0.333333   \n",
       "4   -0.466667  0.733333  -0.466667        -0.2         0.6   0.333333   \n",
       "\n",
       "      feat12     feat13      feat14     feat15      feat16  feat17  \n",
       "0  0.0666667       -0.6   0.0666667  -0.466667   0.0666667     NaN  \n",
       "1  0.0666667       -0.6  -0.0666667       -0.2    0.466667     NaN  \n",
       "2       -0.2  -0.866667         0.2       -0.6  -0.0666667     NaN  \n",
       "3  -0.333333  -0.866667         0.2  -0.733333   0.0666667     NaN  \n",
       "4  -0.466667  -0.733333    0.466667  -0.733333   -0.466667     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['feat1','feat2','feat3','feat4','feat5','feat6','feat7','feat8','feat9','feat10','feat11','feat12','feat13','feat14','feat15','feat16']\n",
    "# Removing the first two characters in every data attribute value.\n",
    "for c in columns:\n",
    "    test_data[c] = test_data[c].str.split(':').str[1]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alphabet    False\n",
       "feat1       False\n",
       "feat2       False\n",
       "feat3       False\n",
       "feat4       False\n",
       "feat5       False\n",
       "feat6       False\n",
       "feat7       False\n",
       "feat8       False\n",
       "feat9       False\n",
       "feat10      False\n",
       "feat11      False\n",
       "feat12      False\n",
       "feat13      False\n",
       "feat14      False\n",
       "feat15      False\n",
       "feat16      False\n",
       "feat17       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.dropna(axis=1,how='all')\n",
    "test_data=test_data.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphabet</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>feat15</th>\n",
       "      <th>feat16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alphabet       feat1       feat2      feat3       feat4      feat5  \\\n",
       "0        26   -0.733333   -0.466667  -0.466667        -0.6  -0.733333   \n",
       "1        16   -0.466667  -0.0666667  -0.333333   -0.333333  -0.333333   \n",
       "2        19  -0.0666667    0.333333  0.0666667  -0.0666667  -0.466667   \n",
       "3         8   -0.466667         0.2  -0.333333  -0.0666667  -0.466667   \n",
       "4         8        -0.2  -0.0666667  0.0666667   -0.333333  -0.466667   \n",
       "\n",
       "        feat6       feat7      feat8       feat9      feat10      feat11  \\\n",
       "0  -0.0666667   0.0666667  -0.733333         0.2    0.466667  -0.0666667   \n",
       "1   -0.333333         0.2       -0.2   -0.466667   0.0666667  -0.0666667   \n",
       "2   0.0666667   0.0666667  -0.333333    0.333333    0.466667   -0.733333   \n",
       "3  -0.0666667  -0.0666667   0.733333   -0.866667  -0.0666667        -0.2   \n",
       "4  -0.0666667        -0.2       -0.6  -0.0666667    0.333333  -0.0666667   \n",
       "\n",
       "       feat12     feat13     feat14      feat15      feat16  \n",
       "0  -0.0666667  -0.866667  0.0666667   -0.333333        -0.2  \n",
       "1         0.2  -0.733333        0.2  -0.0666667    0.333333  \n",
       "2   0.0666667  -0.733333  -0.333333   -0.333333    0.333333  \n",
       "3   0.0666667       -0.6  0.0666667          -1   0.0666667  \n",
       "4         0.2       -0.6  0.0666667        -0.6  -0.0666667  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alphabet</th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>feat11</th>\n",
       "      <th>feat12</th>\n",
       "      <th>feat13</th>\n",
       "      <th>feat14</th>\n",
       "      <th>feat15</th>\n",
       "      <th>feat16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>-0.0666667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.866667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.0666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0666667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alphabet      feat1       feat2      feat3      feat4      feat5  \\\n",
       "0        17  -0.466667  -0.0666667  -0.333333       -0.2  -0.733333   \n",
       "1        18       -0.6         0.2  -0.466667       -0.2       -0.6   \n",
       "2         6  -0.733333   -0.866667  -0.733333  -0.733333  -0.866667   \n",
       "3         6  -0.733333   -0.466667  -0.466667       -0.6  -0.733333   \n",
       "4        20  -0.333333   0.0666667       -0.2       -0.2       -0.6   \n",
       "\n",
       "        feat6     feat7      feat8       feat9      feat10     feat11  \\\n",
       "0   0.0666667      -0.2  0.0666667        -0.2        -0.2       -0.2   \n",
       "1   -0.333333  0.333333        0.2        -0.6  -0.0666667  -0.466667   \n",
       "2   -0.333333  0.333333  -0.466667   -0.333333    0.333333        0.2   \n",
       "3  -0.0666667       0.2  -0.866667  -0.0666667    0.733333  -0.333333   \n",
       "4   -0.466667  0.733333  -0.466667        -0.2         0.6   0.333333   \n",
       "\n",
       "      feat12     feat13      feat14     feat15      feat16  \n",
       "0  0.0666667       -0.6   0.0666667  -0.466667   0.0666667  \n",
       "1  0.0666667       -0.6  -0.0666667       -0.2    0.466667  \n",
       "2       -0.2  -0.866667         0.2       -0.6  -0.0666667  \n",
       "3  -0.333333  -0.866667         0.2  -0.733333   0.0666667  \n",
       "4  -0.466667  -0.733333    0.466667  -0.733333   -0.466667  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing features along with their label's are defined.\n",
    "training_features=train_data.drop('Alphabet',axis=1)\n",
    "train_label=train_data['Alphabet']\n",
    "testing_features=test_data.drop('Alphabet',axis=1)\n",
    "test_label=test_data['Alphabet']\n",
    "X_train=training_features\n",
    "y_train=train_label\n",
    "X_test=testing_features\n",
    "y_test=test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9514\n"
     ]
    }
   ],
   "source": [
    "#Initial neighbours count=5 to get and understanding.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "start_time=time.time()\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "end_time=time.time()\n",
    "y_pred = classifier.predict(X_test) # Prediction of the classifier\n",
    "score=accuracy_score(y_test,y_pred) # Accuracy given by the accuracy_score metric.\n",
    "print(score)\n",
    "#end_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.05687212944030762s\n",
      "[[190   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   3   0]\n",
      " [  0 188   0   1   3   0   0   3   0   0   0   0   0   1   0   0   0   2\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  0   0 173   0   2   0   2   0   0   0   0   0   0   1   3   0   0   0\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  0   2   0 204   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   1   0 192   0   3   0   0   0   2   0   0   0   0   0   0   0\n",
      "    0   0   0   1   0   2   0   1]\n",
      " [  0   0   0   1   1 196   0   0   0   1   0   0   0   0   0   9   0   0\n",
      "    0   1   0   1   0   0   0   0]\n",
      " [  0   1   1   3   2   0 213   0   0   0   0   0   1   0   3   0   0   0\n",
      "    0   0   0   1   1   0   0   0]\n",
      " [  0   5   0   4   0   0   2 174   0   0   5   0   0   0   1   0   0   0\n",
      "    0   0   1   1   0   2   0   1]\n",
      " [  0   0   0   1   0   1   0   0 177   9   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   1   0   1   9 160   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   2   0   1   9   0   0 147   0   0   0   0   0   0   1\n",
      "    0   0   0   0   0   6   0   0]\n",
      " [  0   0   1   0   1   0   0   0   0   0   0 199   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0 182   0   0   0   0   0\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2   0   0   0   0   0 174   0   0   0   2\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   2   5   0   0   0   0   0   0   0   0   0   1 168   0   1   0\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0  12   0   0   0   0   0   0   0   0   0 193   0   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   2   0   0   0   0   0   0   0   8   1 177   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0  10   0   0   0   0   0   3   0   0   4   3   0   2   0   0   0 168\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   1   2   2   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "  177   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0 193   0   0   0   0   2   0]\n",
      " [  0   0   0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0 203   0   0   0   0   0]\n",
      " [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   1 178   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   0   0   0\n",
      "    0   0   0   0 173   0   0   0]\n",
      " [  0   0   0   2   4   0   0   0   0   0   3   0   0   0   1   0   0   0\n",
      "    2   2   0   0   0 190   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   2   0   0 181   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   2   0\n",
      "    1   0   0   0   0   0   0 187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.97      0.98       195\n",
      "           2       0.88      0.94      0.91       199\n",
      "           3       0.97      0.95      0.96       182\n",
      "           4       0.91      0.99      0.95       207\n",
      "           5       0.91      0.95      0.93       203\n",
      "           6       0.92      0.93      0.92       210\n",
      "           7       0.96      0.94      0.95       226\n",
      "           8       0.90      0.89      0.89       196\n",
      "           9       0.95      0.94      0.95       188\n",
      "          10       0.94      0.93      0.93       172\n",
      "          11       0.91      0.88      0.90       167\n",
      "          12       0.98      0.99      0.99       201\n",
      "          13       0.98      0.98      0.98       185\n",
      "          14       0.96      0.98      0.97       178\n",
      "          15       0.91      0.94      0.92       179\n",
      "          16       0.95      0.94      0.94       206\n",
      "          17       0.98      0.94      0.96       189\n",
      "          18       0.96      0.88      0.92       190\n",
      "          19       0.98      0.96      0.97       185\n",
      "          20       0.98      0.98      0.98       197\n",
      "          21       0.99      0.98      0.99       207\n",
      "          22       0.95      0.97      0.96       183\n",
      "          23       0.98      0.98      0.98       176\n",
      "          24       0.95      0.93      0.94       204\n",
      "          25       0.97      0.98      0.98       184\n",
      "          26       0.98      0.98      0.98       191\n",
      "\n",
      "    accuracy                           0.95      5000\n",
      "   macro avg       0.95      0.95      0.95      5000\n",
      "weighted avg       0.95      0.95      0.95      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(f\"Training time: {end_time-start_time}s\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred)) # report generated to identify all the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Error')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')\n",
    "#https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952\n",
      "Training time: 0.05642223358154297s\n",
      "[[191   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   2   0]\n",
      " [  0 190   0   1   2   0   0   2   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  0   0 175   0   2   0   2   0   0   0   0   0   0   1   1   0   0   0\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  0   4   0 200   0   0   0   2   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   2   4   0 187   0   4   0   0   0   2   0   0   0   0   0   0   0\n",
      "    1   0   0   1   0   1   0   1]\n",
      " [  0   0   0   2   1 193   0   0   0   2   0   0   0   0   0   8   0   0\n",
      "    0   3   0   1   0   0   0   0]\n",
      " [  0   1   2   4   4   0 210   0   0   0   0   0   0   0   3   0   0   0\n",
      "    0   0   0   1   1   0   0   0]\n",
      " [  0   4   0   5   0   0   1 177   0   0   5   0   0   1   0   0   0   0\n",
      "    0   0   1   1   0   0   0   1]\n",
      " [  0   0   0   1   0   0   0   0 178   9   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   2   0   1   8 160   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   2   2   0   1   8   0   0 147   0   0   0   0   0   0   1\n",
      "    0   0   0   0   0   6   0   0]\n",
      " [  0   0   1   0   0   0   0   0   1   0   0 198   0   0   0   0   1   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0 181   0   0   0   0   0\n",
      "    0   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   2   0   0   0   0   0 174   1   0   0   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   4   0   0   0   0   0   0   0   0   0   1 171   0   1   0\n",
      "    0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   1   0  10   0   0   0   0   0   0   0   0   0 194   0   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   3   0   0   0   0   0   0   0   7   0 178   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   9   0   3   0   1   0   1   0   0   4   1   0   0   0   0   0 170\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  1   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  181   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0 193   0   0   0   0   2   0]\n",
      " [  1   0   0   1   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 203   0   0   0   0   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 179   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0\n",
      "    0   0   0   0 174   0   0   0]\n",
      " [  0   0   0   3   5   0   0   0   1   0   1   0   0   0   1   0   1   0\n",
      "    1   1   1   0   0 189   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   2   0   2   0   0 180   0]\n",
      " [  0   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   2   0\n",
      "    0   0   0   0   0   0   0 187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.98      0.98       195\n",
      "           2       0.88      0.95      0.91       199\n",
      "           3       0.96      0.96      0.96       182\n",
      "           4       0.88      0.97      0.92       207\n",
      "           5       0.91      0.92      0.92       203\n",
      "           6       0.93      0.92      0.92       210\n",
      "           7       0.95      0.93      0.94       226\n",
      "           8       0.91      0.90      0.91       196\n",
      "           9       0.95      0.95      0.95       188\n",
      "          10       0.93      0.93      0.93       172\n",
      "          11       0.92      0.88      0.90       167\n",
      "          12       0.99      0.99      0.99       201\n",
      "          13       0.99      0.98      0.98       185\n",
      "          14       0.98      0.98      0.98       178\n",
      "          15       0.93      0.96      0.94       179\n",
      "          16       0.96      0.94      0.95       206\n",
      "          17       0.97      0.94      0.96       189\n",
      "          18       0.96      0.89      0.93       190\n",
      "          19       0.99      0.98      0.98       185\n",
      "          20       0.97      0.98      0.97       197\n",
      "          21       0.99      0.98      0.98       207\n",
      "          22       0.95      0.98      0.96       183\n",
      "          23       0.98      0.99      0.99       176\n",
      "          24       0.96      0.93      0.95       204\n",
      "          25       0.98      0.98      0.98       184\n",
      "          26       0.98      0.98      0.98       191\n",
      "\n",
      "    accuracy                           0.95      5000\n",
      "   macro avg       0.95      0.95      0.95      5000\n",
      "weighted avg       0.95      0.95      0.95      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "classifier = KNeighborsClassifier(n_neighbors=3) # The value taken from the graph.\n",
    "classifier.fit(X_train, y_train)\n",
    "end_time=time.time()\n",
    "y_pred_3 = classifier.predict(X_test)\n",
    "score=accuracy_score(y_test,y_pred_3)\n",
    "print(score)\n",
    "print(f\"Training time: {end_time-start_time}s\")\n",
    "print(confusion_matrix(y_test, y_pred_3))\n",
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941\n",
      "Training time: 0.05112791061401367s\n",
      "[[191   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  0 194   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  0   0 171   0   3   0   2   0   0   0   0   0   1   0   3   0   0   0\n",
      "    0   0   1   0   1   0   0   0]\n",
      " [  0   3   0 200   0   0   0   1   0   1   0   0   0   0   1   0   0   0\n",
      "    0   1   0   0   0   0   0   0]\n",
      " [  0   1   0   0 190   0   2   0   0   0   3   0   0   0   0   0   0   0\n",
      "    1   0   0   1   0   2   0   3]\n",
      " [  0   0   0   1   1 195   0   0   0   2   0   0   0   0   0   5   0   0\n",
      "    0   4   0   2   0   0   0   0]\n",
      " [  0   1   3   4   3   0 206   0   0   0   0   0   0   0   4   0   2   0\n",
      "    0   0   0   1   1   1   0   0]\n",
      " [  0   3   0   7   0   0   2 167   0   0   6   0   0   0   1   0   0   4\n",
      "    0   0   2   0   0   2   1   1]\n",
      " [  0   0   0   1   0   1   0   0 179   7   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   1   1   0   1   9 159   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   2   2   0   0   6   0   0 146   0   0   0   0   0   0   4\n",
      "    0   0   0   0   0   6   0   0]\n",
      " [  0   0   1   0   2   0   1   0   0   0   0 193   0   0   0   0   1   1\n",
      "    0   0   0   0   0   2   0   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   2   0 177   1   0   0   0   0\n",
      "    0   0   0   2   0   0   0   0]\n",
      " [  0   0   0   2   0   0   0   1   0   0   0   0   0 169   3   0   0   3\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   1   5   0   0   0   0   0   0   0   0   0   0 168   0   3   0\n",
      "    0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   2   0   9   0   0   0   0   0   0   0   0   0 192   0   0\n",
      "    1   1   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   0   1   0   0   0   1   0   0   0  11   0 174   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   8   0   1   1   0   0   3   0   0   1   2   0   1   1   0   0 171\n",
      "    0   0   1   0   0   0   0   0]\n",
      " [  0   2   0   1   1   1   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "  176   0   0   0   0   1   0   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0 193   0   0   0   0   3   0]\n",
      " [  1   0   0   0   0   0   0   2   0   0   1   0   1   0   1   0   0   0\n",
      "    0   0 201   0   0   0   0   0]\n",
      " [  0   3   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 177   1   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0   2   0   0   0\n",
      "    0   0   0   0 171   0   0   0]\n",
      " [  0   0   0   3   3   0   0   0   0   0   5   1   0   0   1   0   0   2\n",
      "    3   3   2   0   0 181   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   2   0   0 182   0]\n",
      " [  0   0   0   0   1   1   0   0   0   1   0   0   0   0   0   0   1   0\n",
      "    3   0   0   0   0   2   0 182]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.98      0.98       195\n",
      "           2       0.88      0.97      0.92       199\n",
      "           3       0.97      0.94      0.96       182\n",
      "           4       0.87      0.97      0.92       207\n",
      "           5       0.91      0.94      0.92       203\n",
      "           6       0.93      0.93      0.93       210\n",
      "           7       0.96      0.91      0.94       226\n",
      "           8       0.92      0.85      0.89       196\n",
      "           9       0.95      0.95      0.95       188\n",
      "          10       0.94      0.92      0.93       172\n",
      "          11       0.88      0.87      0.88       167\n",
      "          12       0.97      0.96      0.97       201\n",
      "          13       0.97      0.96      0.96       185\n",
      "          14       0.99      0.95      0.97       178\n",
      "          15       0.85      0.94      0.89       179\n",
      "          16       0.97      0.93      0.95       206\n",
      "          17       0.96      0.92      0.94       189\n",
      "          18       0.90      0.90      0.90       190\n",
      "          19       0.96      0.95      0.95       185\n",
      "          20       0.96      0.98      0.97       197\n",
      "          21       0.97      0.97      0.97       207\n",
      "          22       0.95      0.97      0.96       183\n",
      "          23       0.98      0.97      0.98       176\n",
      "          24       0.92      0.89      0.90       204\n",
      "          25       0.97      0.99      0.98       184\n",
      "          26       0.97      0.95      0.96       191\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.94      0.94      0.94      5000\n",
      "weighted avg       0.94      0.94      0.94      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "classifier = KNeighborsClassifier(n_neighbors=15) # To identify how the classifier works with higher number of neighbours.\n",
    "classifier.fit(X_train, y_train)\n",
    "end_time=time.time()\n",
    "y_pred_4 = classifier.predict(X_test)\n",
    "score=accuracy_score(y_test,y_pred_4)\n",
    "print(score)\n",
    "print(f\"Training time: {end_time-start_time}s\")\n",
    "print(confusion_matrix(y_test, y_pred_4))\n",
    "print(classification_report(y_test, y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "rfc=RandomForestClassifier(n_estimators=600) # 600 estimators is taken as a random value to go more depth in treewise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_rf=time.time()\n",
    "rfc.fit(X_train,y_train)\n",
    "end_time_rf=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rfc.predict(X_test) # Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 9.124819278717041s\n",
      "0.965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99       195\n",
      "           2       0.91      0.97      0.94       199\n",
      "           3       0.98      0.95      0.96       182\n",
      "           4       0.96      0.98      0.97       207\n",
      "           5       0.95      0.94      0.94       203\n",
      "           6       0.97      0.96      0.96       210\n",
      "           7       0.96      0.93      0.95       226\n",
      "           8       0.93      0.94      0.93       196\n",
      "           9       0.97      0.94      0.95       188\n",
      "          10       0.95      0.95      0.95       172\n",
      "          11       0.92      0.95      0.93       167\n",
      "          12       0.99      0.97      0.98       201\n",
      "          13       0.96      0.98      0.97       185\n",
      "          14       0.99      0.98      0.99       178\n",
      "          15       0.96      0.96      0.96       179\n",
      "          16       0.97      0.98      0.97       206\n",
      "          17       0.97      0.97      0.97       189\n",
      "          18       0.94      0.97      0.96       190\n",
      "          19       0.98      0.95      0.97       185\n",
      "          20       0.98      0.99      0.98       197\n",
      "          21       0.98      0.98      0.98       207\n",
      "          22       0.96      0.98      0.97       183\n",
      "          23       0.98      0.99      0.99       176\n",
      "          24       0.97      0.97      0.97       204\n",
      "          25       0.99      0.96      0.98       184\n",
      "          26       0.98      0.98      0.98       191\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.97      0.97      0.97      5000\n",
      "weighted avg       0.97      0.96      0.97      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(predictions,y_test)\n",
    "print(f\"Training time: {end_time_rf-start_time_rf}s\")\n",
    "print(score)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.9365839958190918s\n",
      "0.9598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.99      0.99       195\n",
      "           2       0.89      0.96      0.93       199\n",
      "           3       0.98      0.95      0.97       182\n",
      "           4       0.93      0.97      0.95       207\n",
      "           5       0.95      0.95      0.95       203\n",
      "           6       0.93      0.95      0.94       210\n",
      "           7       0.95      0.93      0.94       226\n",
      "           8       0.92      0.90      0.91       196\n",
      "           9       0.97      0.95      0.96       188\n",
      "          10       0.96      0.95      0.95       172\n",
      "          11       0.90      0.96      0.93       167\n",
      "          12       1.00      0.97      0.98       201\n",
      "          13       0.97      0.99      0.98       185\n",
      "          14       0.99      0.97      0.98       178\n",
      "          15       0.96      0.95      0.95       179\n",
      "          16       0.97      0.95      0.96       206\n",
      "          17       0.96      0.96      0.96       189\n",
      "          18       0.94      0.94      0.94       190\n",
      "          19       0.97      0.96      0.96       185\n",
      "          20       0.98      0.99      0.99       197\n",
      "          21       0.98      0.97      0.97       207\n",
      "          22       0.96      0.96      0.96       183\n",
      "          23       0.98      0.99      0.99       176\n",
      "          24       0.99      0.96      0.98       204\n",
      "          25       0.98      0.96      0.97       184\n",
      "          26       0.98      0.97      0.98       191\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.96      0.96      0.96      5000\n",
      "weighted avg       0.96      0.96      0.96      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc1=RandomForestClassifier(n_estimators=60) # value 6000 was tried, but was taking too long so found the performance of 60 estimators\n",
    "start_time_rf1=time.time()\n",
    "rfc1.fit(X_train,y_train)\n",
    "end_time_rf1=time.time()\n",
    "predictions_1=rfc1.predict(X_test)\n",
    "score=accuracy_score(predictions_1,y_test)\n",
    "print(f\"Training time: {end_time_rf1-start_time_rf1}s\")\n",
    "print(score)\n",
    "print(classification_report(y_test,predictions_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.1277461051940918s\n",
      "0.9152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.98      0.96       195\n",
      "           2       0.74      0.92      0.82       199\n",
      "           3       0.90      0.91      0.90       182\n",
      "           4       0.86      0.95      0.90       207\n",
      "           5       0.89      0.90      0.89       203\n",
      "           6       0.89      0.91      0.90       210\n",
      "           7       0.93      0.88      0.90       226\n",
      "           8       0.82      0.84      0.83       196\n",
      "           9       0.94      0.93      0.94       188\n",
      "          10       0.94      0.91      0.93       172\n",
      "          11       0.86      0.89      0.88       167\n",
      "          12       0.97      0.92      0.94       201\n",
      "          13       0.95      0.96      0.96       185\n",
      "          14       0.96      0.91      0.94       178\n",
      "          15       0.87      0.91      0.89       179\n",
      "          16       0.93      0.91      0.92       206\n",
      "          17       0.94      0.88      0.91       189\n",
      "          18       0.92      0.85      0.88       190\n",
      "          19       0.91      0.92      0.91       185\n",
      "          20       0.93      0.94      0.94       197\n",
      "          21       0.95      0.92      0.93       207\n",
      "          22       0.95      0.92      0.94       183\n",
      "          23       0.98      0.97      0.97       176\n",
      "          24       0.96      0.91      0.93       204\n",
      "          25       0.98      0.93      0.96       184\n",
      "          26       0.97      0.91      0.94       191\n",
      "\n",
      "    accuracy                           0.92      5000\n",
      "   macro avg       0.92      0.92      0.92      5000\n",
      "weighted avg       0.92      0.92      0.92      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc2=RandomForestClassifier(n_estimators=6) # 6 is taken to get a more deeper understanding about how the classifier works.\n",
    "start_time_rf2=time.time()\n",
    "rfc2.fit(X_train,y_train)\n",
    "end_time_rf2=time.time()\n",
    "predictions_2=rfc2.predict(X_test)\n",
    "score=accuracy_score(predictions_2,y_test)\n",
    "print(f\"Training time: {end_time_rf2-start_time_rf2}s\")\n",
    "print(score)\n",
    "print(classification_report(y_test,predictions_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Comparing these two classifiers with different values, Random Forest works good for this dataset around 96.5% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
